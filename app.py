# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jr3HnLejNXYYHqAYR9z-BkdpP_9YmcE5
"""
"""
import os

train_path = 'C:/Users/vkesh/Downloads/currency/train/Train'
valid_path = 'C:/Users/vkesh/Downloads/currency/test/Test'

print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))
import tensorflow as tf
import tensorflow 
from tensorflow import keras
from keras.layers import Input, Lambda, Dense, Flatten, MaxPooling2D, Conv2D
from keras.models import Model, Sequential


from keras.preprocessing import image

from keras.utils.image_dataset_from_directory import ImageDataGenerator,load_img

import numpy as np

IMAGE_SIZE = [224, 224]

train_path = "C:/Users/vkesh/Downloads/currency/train/Train"
valid_path = "C:/Users/vkesh/Downloads/currency/test/Test"


import glob2 as glob

folders = glob.glob('C:/Users/vkesh/Downloads/currency/train/Train/*')

folders
 
from keras.models import Sequential

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

print(Conv2D)

Classifier=Sequential()

Classifier.add(Conv2D(32,(3,3), input_shape=(224,224,3), activation='relu'))
Classifier.add(MaxPooling2D(pool_size=(2,2)))

Classifier.add(Conv2D(32,(3,3),activation='relu'))
Classifier.add(MaxPooling2D(pool_size=(2,2)))

Classifier.add(Flatten())

Classifier.add(Dense(units = 128, activation = 'relu'))
Classifier.add(Dense(units = 7, activation = 'softmax'))

Classifier.compile(
  loss='categorical_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   height_shift_range=0.2,
                                   featurewise_center=True,
                                   rotation_range=0.4,
                                   horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255,)

training_set = train_datagen.flow_from_directory('C:/Users/vkesh/Downloads/currency/train/Train',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical')

test_set = test_datagen.flow_from_directory('C:/Users/vkesh/Downloads/currency/test/Test',
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

from PIL import _imaging
from PIL import Image
import PIL
# Run the cell. It will take some time to execute
r = Classifier.fit(
  training_set,
  validation_data=test_set,
  epochs=50,
  steps_per_epoch=len(training_set),
  validation_steps=len(test_set)
)

r.history

import matplotlib.pyplot as plt
# plot the loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

from keras.models import load_model

Classifier.save('model_Classifier.h5')

y_pred = Classifier.predict(test_set)

y_pred

import numpy as np
y_pred = np.argmax(y_pred, axis=1)

y_pred


from keras.models import load_model

from keras.preprocessing import image

model_path = "C:/Users/vkesh/Downloads/currency/model_Classifier.h5"

model = load_model(model_path)

print(globals())

model=load_model('model_Classifier.h5')

img=image.load_img('C:/Users/vkesh/Downloads/currency/train/Train/1Hundrednote/2.jpg',target_size=(224,224))

img

test_image=image.img_to_array(img)
test_image=np.expand_dims(test_image, axis = 0)

result = Classifier.predict(test_image)
result

a=np.argmax(model.predict(test_image), axis=1)

a==5

a==0

"""
"""
import os
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Define the paths to training and validation data
train_path = 'C:/Users/vkesh/Downloads/currency/train/Train'
valid_path = 'C:/Users/vkesh/Downloads/currency/test/Test'

# Check if the training and validation data exists
print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))

# Define image dimensions
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32

# Create image data generators
train_datagen = ImageDataGenerator(
    rescale = 1./255,
    height_shift_range=0.2,
    featurewise_center=True,
    rotation_range=0.4,
    horizontal_flip = True
)

test_datagen = ImageDataGenerator(rescale = 1./255)

# Generate batches of augmented data
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size = IMAGE_SIZE,
    batch_size = BATCH_SIZE,
    class_mode = 'categorical'
)

validation_generator = test_datagen.flow_from_directory(
    valid_path,
    target_size = IMAGE_SIZE,
    batch_size = BATCH_SIZE,
    class_mode = 'categorical'
)

# Build the CNN model
model = Sequential()

model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())

model.add(Dense(units=128, activation='relu'))
model.add(Dense(units=7, activation='softmax'))

# Compile the model
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=50,
    steps_per_epoch=len(train_generator),
    validation_steps=len(validation_generator)
)

# Save the model
model.save('model_Classifier.h5')

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.applications import VGG16
from keras.callbacks import LearningRateScheduler

# Define the paths to training and validation data
train_path = 'C:/Users/vkesh/Downloads/currency/train'
valid_path = 'C:/Users/vkesh/Downloads/currency/test/test'

# Check if the training and validation data exists
print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))

# Define image dimensions
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = 7
EPOCHS = 50

# Create image data generators with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    valid_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Load the pre-trained VGG16 model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the convolutional layers of the VGG16 base model
for layer in base_model.layers:
    layer.trainable = False

# Create a custom model by adding layers on top of the base model
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dense(NUM_CLASSES, activation='softmax')
])

# Define a learning rate scheduler to decrease the learning rate after a certain number of epochs
def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

lr_scheduler = LearningRateScheduler(scheduler)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    steps_per_epoch=len(train_generator),
    validation_steps=len(validation_generator),
    callbacks=[lr_scheduler]
)

# Save the model
model.save('model_Classifier.h5')

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.applications import MobileNetV2
from keras.callbacks import LearningRateScheduler
from keras.mixed_precision import experimental as mixed_precision

# Set mixed precision policy
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)

# Define the paths to training and validation data
train_path = 'C:/Users/vkesh/Downloads/currency/train'
valid_path = 'C:/Users/vkesh/Downloads/currency/test/test'

# Check if the training and validation data exists
print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))

# Define image dimensions
IMAGE_SIZE = (160, 160)  # Smaller image size
BATCH_SIZE = 16  # Reduce batch size
NUM_CLASSES = 7
EPOCHS = 50

# Create image data generators with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    valid_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Load the pre-trained MobileNetV2 model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))

# Freeze the convolutional layers of the MobileNetV2 base model
for layer in base_model.layers:
    layer.trainable = False

# Create a custom model by adding layers on top of the base model
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dense(NUM_CLASSES, activation='softmax')
])

# Define a learning rate scheduler to decrease the learning rate after a certain number of epochs
def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

lr_scheduler = LearningRateScheduler(scheduler)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    steps_per_epoch=len(train_generator),
    validation_steps=len(validation_generator),
    callbacks=[lr_scheduler]
)

# Save the model
model.save('model_Classifier.h5')



import os
import numpy as np
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.applications import MobileNetV2

# Define the paths to training and validation data
train_path = 'C:/Users/vkesh/Downloads/currency/train/training'
valid_path = 'C:/Users/vkesh/Downloads/currency/vaid/validation'

# Check if the training and validation data exists
print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))

# Define image dimensions
IMAGE_SIZE = (224, 224)  # Standard image size for MobileNetV2
BATCH_SIZE = 16
NUM_CLASSES = 7
EPOCHS = 50

# Create image data generators with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    valid_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Load the pre-trained MobileNetV2 model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the convolutional layers of the MobileNetV2 base model
for layer in base_model.layers:
    layer.trainable = False

# Create a custom model by adding layers on top of the base model
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dense(NUM_CLASSES, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    steps_per_epoch=len(train_generator),
    validation_steps=len(validation_generator)
)

# Save the model
model.save('model_Classifier.h5')
"""
"""
import os
import numpy as np
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.applications import MobileNetV2

# Define the paths to training and validation data
train_path = 'C:/Users/vkesh/Downloads/currency/train/training'
valid_path = 'C:/Users/vkesh/Downloads/currency/vaid/validation'

# Check if the training and validation data exists
print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))

# Define image dimensions
IMAGE_SIZE = (224, 224)  # Standard image size for MobileNetV2
BATCH_SIZE = 32
NUM_CLASSES = 7
EPOCHS = 50

# Create image data generators with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,  # Decreased rotation range
    width_shift_range=0.1,  # Decreased width shift range
    height_shift_range=0.1,  # Decreased height shift range
    shear_range=0.1,  # Decreased shear range
    zoom_range=0.1,  # Decreased zoom range
    horizontal_flip=True,
    fill_mode='nearest'
)


test_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle= False
)

validation_generator = test_datagen.flow_from_directory(
    valid_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle= False
)

# Load the pre-trained MobileNetV2 model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the convolutional layers of the MobileNetV2 base model
for layer in base_model.layers:
    layer.trainable = False
# Create a custom model by adding layers on top of the base model
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),  # Added dropout layer
    Dense(NUM_CLASSES, activation='softmax')
])

# Compile the model with Adam optimizer and lower learning rate
model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model with early stopping
early_stopping = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)

history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    steps_per_epoch=len(train_generator),
    validation_steps=len(validation_generator),
    callbacks=[early_stopping]
)

# Save the model
model.save('model_Classifier.h5')
"""
import os
import numpy as np
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.applications import MobileNetV2
import cv2
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define the paths to training and validation data
train_path = 'C:/Users/vkesh/Downloads/currency/train/training'
valid_path = 'C:/Users/vkesh/Downloads/currency/vaid/validation'

# Check if the training and validation data exists
print("Training Data Exists:", os.path.exists(train_path))
print("Validation Data Exists:", os.path.exists(valid_path))

# Define image dimensions
IMAGE_SIZE = (224, 224)  # Standard image size for MobileNetV2
BATCH_SIZE = 16
NUM_CLASSES = 7
EPOCHS = 50

# Create image data generators with data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    valid_path,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Load the pre-trained MobileNetV2 model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the convolutional layers of the MobileNetV2 base model
for layer in base_model.layers:
    layer.trainable = False

# Create a custom model by adding layers on top of the base model
model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dense(NUM_CLASSES, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    steps_per_epoch=len(train_generator),
    validation_steps=len(validation_generator)
)

# Save the model
model.save('model_Classifier.h5')

# Visualize training history
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate model on test set
test_loss, test_accuracy = model.evaluate(validation_generator)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

# Load class labels
class_labels = list(train_generator.class_indices.keys())

# Confusion matrix
predictions = model.predict(validation_generator)
y_pred = np.argmax(predictions, axis=1)
y_true = validation_generator.classes

confusion_matrix = pd.crosstab(
    pd.Series(y_true, name='Actual'),
    pd.Series(y_pred, name='Predicted')
)
plt.figure(figsize=(10, 8))
sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks(ticks=np.arange(len(class_labels)) + 0.5, labels=class_labels, rotation=45)
plt.yticks(ticks=np.arange(len(class_labels)) + 0.5, labels=class_labels, rotation=0)
plt.show()

# Correlation analysis
train_df = pd.DataFrame(history.history)
correlation_matrix = train_df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', cbar=True)
plt.title('Correlation Matrix of Training History')
plt.show()
